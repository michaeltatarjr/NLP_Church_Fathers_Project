{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00462afa",
   "metadata": {},
   "source": [
    "## In this notebook, we will:\n",
    " * read in the files\n",
    " * compute document vectors, using Doc2Vec\n",
    " * compute the cosine similaritys\n",
    " * The end goal is to have a heatmap, showing text similarities between corpus's (this will likely include multiple heatmaps)\n",
    " * Note, start with Doc2Vec then try w/ cosine similarity, but it may be better to use soft cosine similarity.  \n",
    " * In a practial sense, this would be reading in pre-tokenized the corpora, then further tokenizing with Doc2Vec, then\n",
    " * ...building a model, then running it on whatever corpora is relevant?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9562af5",
   "metadata": {},
   "source": [
    "### General Considerations:\n",
    " 1. We might have to start small....perhaps just break off a single text, then compare it..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc32e67",
   "metadata": {},
   "source": [
    "#### Workflow:\n",
    "\n",
    " 1. Read docs, and tokenize w, Doc2Vec:\n",
    " 2. Train a model on a corpus to get document vectors.\n",
    " 3. Use the vectors for classification. (apparently you can also use for clustering...)\n",
    " 4. Expand to Cosine Similarity:\n",
    " 5. Calculate vectors using previous vectorization method (Doc2Vec).\n",
    " 6. Compute the cosine similarity between these vectors to determine their similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fcd25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "69d8caf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in file\n",
    "with open('../data/data_tokenized_word/cf_kv_word_tokenized.txt', 'rb') as file:\n",
    "    cf_kv_word_tokenized = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aaa2f5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Address of Tatian to the Greeks\n",
      "Athenagoras the Athenian\n",
      "Clement of Alexandria Exhortation to the Heathen\n",
      "Clement of Alexandria The Salvation of the Rich Man\n",
      "Clement of Alexandria Trilogy\n",
      "Clement of Alexandria, The Stromata\n",
      "Dialogue of Justin, Philosopher and Martyr, with Trypho, a Jew\n",
      "Epistle of Adrian Antoninus and Marcus Aurelius\n",
      "Epistle of Clement of Rome\n",
      "False Ignatius\n",
      "Fragments of Papias\n",
      "Fragments of the Lost Work of Justin on the Resurrection\n",
      "Hippolytus of Rome Expository Treatise Against The Jews.\n",
      "Hippolytus of Rome Treatise On Christ and Antichrist\n",
      "Igantius Syriac Epistles\n",
      "Ignatius Other\n",
      "Ireanaus Against Heresies Book III\n",
      "Ireanaus Fragments from the Lost Writings\n",
      "Irenaeus Against Heresies Book I\n",
      "Irenaeus Against Heresies Book II\n",
      "Irenaeus Against Heresies Book V\n",
      "Ireneaus Against Heresies Book IV\n",
      "Justin's Hortatory Address to the Greeks\n",
      "Origen\n",
      "Tertullian\n",
      "The Didache\n",
      "The Epistle of Barnabas\n",
      "The Epistle of Ignatius to Polycarp\n",
      "The Epistle of Ignatius to the Ephesians\n",
      "The Epistle of Ignatius to the Magnesians\n",
      "The Epistle of Ignatius to the Philadelphians\n",
      "The Epistle of Ignatius to the Romans\n",
      "The Epistle of Ignatius to the Smyrneans\n",
      "The Epistle of Ignatius to the Trallians\n",
      "The Epistle of Mathetes to Diognetus\n",
      "The Epistle of Polycarp to the Philippians\n",
      "The First Apology of Justin\n",
      "The Martyrdom of Ignatius\n",
      "The Martyrdom of Polycarp\n",
      "The Octavius of Minucius Felix\n",
      "The Pastor of Hermas\n",
      "The Second Apology of Justin for the Christians Addressed to the Roman Senate\n",
      "Theophilus of Antioch\n"
     ]
    }
   ],
   "source": [
    "for i in cf_kv_word_tokenized.keys():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "31c94927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using cf_kv as a dictionary to run through TaggedDocument\n",
    "cf_kv_word_tokenized_tagged = {}\n",
    "\n",
    "# Create a list to hold TaggedDocument instances\n",
    "tagged_documents = []\n",
    "\n",
    "for key, value in cf_kv_word_tokenized.items():\n",
    "    tagged_doc = TaggedDocument(words=value, tags=[str(key)])\n",
    "    cf_kv_word_tokenized_tagged[key] = tagged_doc\n",
    "    tagged_documents.append(tagged_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21c9481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Doc2Vec\n",
    "tagged_data = [TaggedDocument(words=(text), tags=[title]) for title, text in texts.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be74e18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
